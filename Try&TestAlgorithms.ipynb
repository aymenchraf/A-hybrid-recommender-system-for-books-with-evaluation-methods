{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Monting google drive, use this if you want to run the file with google colab and save the data in drive."
      ],
      "metadata": {
        "id": "oSbFKEmN3_4p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_VOQQm6exGc",
        "outputId": "a2029bf5-9f09-4b7b-b1da-cd24349def5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# before doing this , copy the CSV files into a folder \"data\" in your drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libs"
      ],
      "metadata": {
        "id": "CqAE7f2a4qvW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWat5Gh0e8tz",
        "outputId": "db712307-9f2a-4f08-fd17-8c06e6ea92a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Collecting scikit-surprise (from surprise)\n",
            "  Downloading scikit-surprise-1.1.3.tar.gz (771 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.0/772.0 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.10.1)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.3-cp310-cp310-linux_x86_64.whl size=3095442 sha256=80dae6f5285f71e7269559f3f529b6d6a802feb106cf8c15ea5582a05e63c909\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/ca/a8/4e28def53797fdc4363ca4af740db15a9c2f1595ebc51fb445\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.3 surprise-0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install surprise #installing it because it is not installed by default\n",
        "from surprise import AlgoBase\n",
        "from surprise import PredictionImpossible\n",
        "from surprise import Dataset\n",
        "from surprise import Reader\n",
        "from surprise.prediction_algorithms.knns import KNNWithMeans\n",
        "from surprise import KNNBasic\n",
        "from surprise import NMF\n",
        "from surprise import accuracy\n",
        "from numpy import random\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from collections import defaultdict\n",
        "from operator import itemgetter\n",
        "import numpy as np\n",
        "import heapq\n",
        "import math\n",
        "import itertools\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import NormalPredictor\n",
        "from surprise.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data provider class, change the ratings path and books path according to your configuration."
      ],
      "metadata": {
        "id": "F5_m5n_g4xaJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eg4JBC6G7db7"
      },
      "outputs": [],
      "source": [
        "class DataProvider:\n",
        "    bookID_to_name = {}\n",
        "    name_to_BookID = {}\n",
        "    ratingsPath = '/content/drive/MyDrive/data/5K_users_ratings.csv'\n",
        "    booksPath = '/content/drive/MyDrive/data/books_data.csv'\n",
        "\n",
        "    def loadData(self):\n",
        "\n",
        "        # Look for files relative to the directory we are running from\n",
        "        os.chdir(os.path.dirname(sys.argv[0]))\n",
        "\n",
        "        ratingsDataset = 0\n",
        "        self.bookID_to_name = {}\n",
        "        self.name_to_BookID = {}\n",
        "\n",
        "        reader = Reader( sep=',', skip_lines=1)\n",
        "\n",
        "        ratingsDataset = Dataset.load_from_file(self.ratingsPath, reader=reader)\n",
        "\n",
        "        with open(self.booksPath, newline='', encoding='UTF-8') as csvfile:\n",
        "            bookReader = csv.reader(csvfile)\n",
        "            next(bookReader)  # Skip header line\n",
        "            for row in bookReader:\n",
        "                bookID = int(row[0])\n",
        "                bookName = row[1]\n",
        "                self.bookID_to_name[bookID] = bookName\n",
        "                self.name_to_BookID[bookName] = bookID\n",
        "        print(ratingsDataset)\n",
        "        return ratingsDataset\n",
        "\n",
        "    def getUserRatings(self, user):\n",
        "        userRatings = []\n",
        "        with open(self.ratingsPath, newline='') as csvfile:\n",
        "            ratingReader = csv.reader(csvfile)\n",
        "            next(ratingReader)\n",
        "            for row in ratingReader:\n",
        "                userID = int(row[0])\n",
        "                if (user == userID):\n",
        "                    book_id = int(row[1])\n",
        "                    rating = float(row[2])\n",
        "                    userRatings.append((book_id, rating))\n",
        "\n",
        "        return userRatings\n",
        "\n",
        "    def getPopularityRanks(self):\n",
        "        ratings = defaultdict(int)\n",
        "        rankings = defaultdict(int)\n",
        "        with open(self.ratingsPath, newline='') as csvfile:\n",
        "            ratingReader = csv.reader(csvfile)\n",
        "            next(ratingReader)\n",
        "            for row in ratingReader:\n",
        "                bookID = int(row[1])\n",
        "                ratings[bookID] += 1\n",
        "        rank = 1\n",
        "        for bookID, ratingCount in sorted(ratings.items(), key=lambda x: x[1], reverse=True):\n",
        "            rankings[bookID] = rank\n",
        "            rank += 1\n",
        "        return rankings\n",
        "\n",
        "    def getGenres(self):\n",
        "        genres = defaultdict(list)\n",
        "        genreIDs = {}\n",
        "        maxGenreID = 0\n",
        "        with open(self.booksPath, newline='', encoding='ISO-8859-1') as csvfile:\n",
        "            bookReader = csv.reader(csvfile)\n",
        "            next(bookReader)  # Skip header line\n",
        "            for row in bookReader:\n",
        "                bookID = int(row[0])\n",
        "                genreList = [x.strip('[] ') for x in row[5].split(',')]\n",
        "                genreIDList = []\n",
        "                for genre in genreList:\n",
        "                    if genre in genreIDs:\n",
        "                        genreID = genreIDs[genre]\n",
        "                    else:\n",
        "                        genreID = maxGenreID\n",
        "                        genreIDs[genre] = genreID\n",
        "                        maxGenreID += 1\n",
        "                    genreIDList.append(genreID)\n",
        "                genres[bookID] = genreIDList\n",
        "        # Convert integer-encoded genre lists to bitfields that we can treat as vectors\n",
        "        for (bookID, genreIDList) in genres.items():\n",
        "            bitfield = [0] * maxGenreID\n",
        "            for genreID in genreIDList:\n",
        "                bitfield[genreID] = 1\n",
        "            genres[bookID] = bitfield\n",
        "        return genres\n",
        "\n",
        "    def getYears(self):\n",
        "        years = defaultdict(int)\n",
        "        with open(self.booksPath, newline='', encoding='ISO-8859-1') as csvfile:\n",
        "            bookReader = csv.reader(csvfile)\n",
        "            next(bookReader)\n",
        "            for row in bookReader:\n",
        "                bookID = int(row[0])\n",
        "                year = int(row[3])\n",
        "                if year:\n",
        "                    years[bookID] = year\n",
        "        return years\n",
        "\n",
        "    def getStandardGeners(self):\n",
        "        geners = defaultdict(list)\n",
        "        with open(self.booksPath, newline='', encoding='ISO-8859-1') as csvfile:\n",
        "            bookReader = csv.reader(csvfile)\n",
        "            next(bookReader)\n",
        "            for row in bookReader:\n",
        "                bookID = int(row[0])\n",
        "                bookGeners = row[5].split(',')\n",
        "                for gener in bookGeners :\n",
        "                  geners[bookID].append(gener)\n",
        "        return geners\n",
        "\n",
        "    def getAuthors(self):\n",
        "        authors = defaultdict(list)\n",
        "        with open(self.booksPath, newline='', encoding='ISO-8859-1') as csvfile:\n",
        "            bookReader = csv.reader(csvfile)\n",
        "            next(bookReader)\n",
        "            for row in bookReader:\n",
        "                bookID = int(row[0])\n",
        "                authors[bookID]=[x.strip('[] ') for x in row[2].split(',')]\n",
        "        return authors\n",
        "\n",
        "    def getBookName(self, bookID):\n",
        "        if bookID in self.bookID_to_name:\n",
        "            return self.bookID_to_name[bookID]\n",
        "        else:\n",
        "            return \"\"\n",
        "\n",
        "    def getBookID(self,bookName):\n",
        "        if bookName in self.name_to_BookID:\n",
        "            return self.name_to_BookID[bookName]\n",
        "        else:\n",
        "            return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CoAlgorithm class, based on KNNm algorithm."
      ],
      "metadata": {
        "id": "Y784CMGM5KP_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KddkD-Mj7kvl"
      },
      "outputs": [],
      "source": [
        "#we use the famous KNN algorithm as one of our recommenders\n",
        "#we dont need to code the hole algo because its on ready exist in suprise lib as \"KNNWithMeans\"\n",
        "class CoAlgorithm(KNNWithMeans):\n",
        "  def __init__(self, k=40):\n",
        "        #init the algorithm , we want the CF user-user not item-item\n",
        "        KNNWithMeans.__init__(self,sim_options={'name': 'cosine','user_based': True})\n",
        "        self.k = k\n",
        "\n",
        "  #fitting the trainset into the algoerithm\n",
        "  #the fit function of KNNWithMeans has on ready a fonction \"compute similarity\" built in\n",
        "  #so we dont need to write one\n",
        "\n",
        "  def fit(self, trainset):\n",
        "        #fiting the data\n",
        "        KNNWithMeans.fit(self, trainset)\n",
        "        \n",
        "\n",
        "  #every algorithm has a function called \"pridect\" \n",
        "  #that uses another function called \"estimate\" that generate the predicted rating      \n",
        "  #the estimate function are on ready built in , so we dont need to define it in this algo\n",
        "  #on other algorithms, we will define it\n",
        "\n",
        "\n",
        "  #the predict function generate a rating between one user and one item\n",
        "  #to predict all estimated ratings of a user i create this function\n",
        "  def EstamedRatingsForUser(self,u):\n",
        "        prid = []\n",
        "        for item in range(self.trainset.n_items):\n",
        "              \n",
        "              rating = self.predict(str(u) , str(self.trainset.to_raw_iid(item)))\n",
        "              prid.append(rating)\n",
        "\n",
        "        return prid"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CBAlgorithm class, a content-based Algorithm"
      ],
      "metadata": {
        "id": "4Q7p4PP95RT6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjMiOlsr7wbT"
      },
      "outputs": [],
      "source": [
        "#extended from an empty recommender template called \"AlgoBase\"\n",
        "class CBAlgorithm(AlgoBase):\n",
        "\n",
        "    def __init__(self, k=40, sim_options={}):\n",
        "        AlgoBase.__init__(self)\n",
        "        self.k = k\n",
        "\n",
        "    def fit(self, trainset , load= False):\n",
        "        #fiting the data\n",
        "        AlgoBase.fit(self, trainset)\n",
        "\n",
        "        # Load up metadata for every book\n",
        "        BD = DataProvider()\n",
        "        genres = BD.getGenres()\n",
        "        years = BD.getYears()\n",
        "        authors = BD.getAuthors()\n",
        "\n",
        "        #if you have a copy od similarities \n",
        "        if load :\n",
        "          self.similarities = self.importSimilarities()\n",
        "          print(\"...done.\")\n",
        "          return self\n",
        "\n",
        "        #generating sim distance for every book combination as a 2x2 matrix\n",
        "        self.similarities = np.zeros((self.trainset.n_items, self.trainset.n_items))\n",
        "\n",
        "        # to calculate it\n",
        "        # Compute item similarity matrix based on content attributes\n",
        "        print(\"Computing content-based similarity matrix...\")\n",
        "        for thisItem in range(self.trainset.n_items):\n",
        "            if (thisItem % 100 == 0):\n",
        "                #just to print the progress every 100 books so you wouldnt suicide\n",
        "                print(thisItem, \" of \", self.trainset.n_items)\n",
        "\n",
        "            for otherItem in range(thisItem+1, self.trainset.n_items):\n",
        "                #get the inner IDs\n",
        "                thisBookID = int(self.trainset.to_raw_iid(thisItem)) \n",
        "                otherBookID = int(self.trainset.to_raw_iid(otherItem))\n",
        "\n",
        "                #get the sub similarities\n",
        "                genreSimilarity = self.computeGenreSimilarity(thisBookID, otherBookID, genres)\n",
        "                if genreSimilarity == 0 :\n",
        "                  sim = 0 \n",
        "                else :\n",
        "                  yearSimilarity = self.computeYearSimilarity(thisBookID, otherBookID, years)\n",
        "                  authorSimilarity = self.computeAuthorSimilarity(thisBookID, otherBookID, authors)\n",
        "                  sim = genreSimilarity * authorSimilarity * yearSimilarity\n",
        "                  \n",
        "                self.similarities[thisItem, otherItem] = sim\n",
        "                self.similarities[otherItem, thisItem] = sim\n",
        "\n",
        "        print(\"...done.\")\n",
        "\n",
        "    \n",
        "\n",
        "    def computeGenreSimilarity(self, book1, book2, genres):\n",
        "        #computing gener similarities with cosine way\n",
        "        genres1 = genres[book1]\n",
        "        genres2 = genres[book2]\n",
        "        sumxx, sumxy, sumyy = 0, 0, 0\n",
        "        for i in range(len(genres1)):\n",
        "            x = genres1[i]\n",
        "            y = genres2[i]\n",
        "            sumxx += x * x\n",
        "            sumyy += y * y\n",
        "            sumxy += x * y\n",
        "        \n",
        "        return sumxy/math.sqrt(sumxx*sumyy)\n",
        "    \n",
        "    #compute year similarities .. this way is not good yet\n",
        "    def computeYearSimilarity(self, book1, book2, years):\n",
        "        diff = abs(years[book1] - years[book2])\n",
        "        return math.exp(-0.007 *diff)\n",
        "\n",
        "\n",
        "\n",
        "    #compute author similarities\n",
        "    def computeAuthorSimilarity(self,book1, book2 , authors):\n",
        "      total_similarities = 0\n",
        "      authors1 = authors[book1]\n",
        "      authors2 = authors[book2]\n",
        "      total_elements = len(authors1) + len(authors2)\n",
        "\n",
        "      for author1 in authors1:\n",
        "          for author2 in authors2:\n",
        "              if author1 == author2: # check if strings are exactly the same\n",
        "                  total_similarities += 1\n",
        "                  break\n",
        "      \n",
        "      similarity_percentage = (total_similarities / total_elements)*2 + 1\n",
        "      return similarity_percentage\n",
        "\n",
        "    def exportSimilarities(self):\n",
        "        np.savetxt('/content/drive/MyDrive/data/CB-Similarities.txt',self.similarities)\n",
        "          \n",
        "\n",
        "    def importSimilarities(self):   \n",
        "      return np.loadtxt('/content/drive/MyDrive/data/CB-Similarities.txt')\n",
        "\n",
        "    #the most important fonction .. \n",
        "    #we calculate the estimate Rating between a user and an item\n",
        "    #the built in function \"predict\" will use this function later\n",
        "    def estimate(self, u, i):\n",
        "\n",
        "        #making sure that the item and user exsit\n",
        "        if not (self.trainset.knows_user(u) and self.trainset.knows_item(i)):\n",
        "            raise PredictionImpossible('User and/or item is unkown.')\n",
        "        \n",
        "        #creating the neighbors list of rated items by the users\n",
        "        neighbors = []\n",
        "        for rating in self.trainset.ur[u]:\n",
        "            Similarity = self.similarities[i,rating[0]]\n",
        "            neighbors.append( (Similarity, rating[1]) )\n",
        "\n",
        "        #picking k neighbors\n",
        "        k_neighbors = heapq.nlargest(self.k, neighbors, key=lambda t: t[0])\n",
        "\n",
        "        # Compute average sim score of K neighbors weighted by user ratings\n",
        "        simTotal = weightedSum = 0\n",
        "        for (simScore, rating) in k_neighbors:\n",
        "            if (simScore > 0):\n",
        "                simTotal += simScore\n",
        "                weightedSum += simScore * rating\n",
        "            \n",
        "        if (simTotal == 0):\n",
        "            raise PredictionImpossible('No neighbors')\n",
        "            \n",
        "        predictedRating = weightedSum/simTotal\n",
        "        return predictedRating\n",
        "    \n",
        "    #to predict all estimated ratings of a user\n",
        "    def EstamedRatingsForUser(self,u):\n",
        "      prid = []\n",
        "      for item in range(self.trainset.n_items):     \n",
        "            rating = self.predict(str(u) , str(self.trainset.to_raw_iid(item)))\n",
        "            prid.append(rating)\n",
        "\n",
        "      return prid"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SGDAlgorithm class, an SGD-based Algorithm."
      ],
      "metadata": {
        "id": "-ZvYkn5m5Xs2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQIqZSTHRrkp"
      },
      "outputs": [],
      "source": [
        "# also extended from an empty recommender template called \"AlgoBase\"\n",
        "class SGDAlgorithm(AlgoBase):\n",
        "\n",
        "    def __init__(self, learning_rate=0.01, n_epochs=20, n_factors=20, reg=0.02):\n",
        "        #initialize the hyperparameters\n",
        "        self.learning_rate = learning_rate\n",
        "        self.n_epochs = n_epochs\n",
        "        self.n_factors = n_factors\n",
        "        self.reg = reg\n",
        "\n",
        "    def fit(self, trainset):\n",
        "        #fitting the trainingset\n",
        "        AlgoBase.fit(self, trainset)\n",
        "\n",
        "        # initialize user and item factors , p for users , q for items\n",
        "        self.users_f = np.random.normal(scale=1.0/self.n_factors, size=(self.trainset.n_users, self.n_factors))\n",
        "        self.books_f = np.random.normal(scale=1.0/self.n_factors, size=(self.trainset.n_items, self.n_factors))\n",
        "\n",
        "        # iterate over epochs and optimize factors using SGD\n",
        "        for _ in range(self.n_epochs):\n",
        "            for userID, bookID, rating in self.trainset.all_ratings():\n",
        "                error = rating - np.dot(self.users_f[userID], self.books_f[bookID])\n",
        "                #correcting the error in user and item factors\n",
        "                self.users_f[userID] += self.learning_rate*(error*self.books_f[bookID]-self.reg*self.users_f[userID])\n",
        "                self.books_f[bookID] += self.learning_rate*(error*self.users_f[userID]-self.reg*self.books_f[bookID])\n",
        "        \n",
        "    \n",
        "    #the most important fonction .. \n",
        "    #we calculate the estimate Rating between a user and an item\n",
        "    #the built in function \"predict\" will use this function later\n",
        "    def estimate(self, u, i):\n",
        "\n",
        "        if not (self.trainset.knows_user(u) and self.trainset.knows_item(i)):\n",
        "            raise PredictionImpossible('User or item is unknown.')\n",
        "\n",
        "        #the estimated rating is the dot bettwen item and user learned factors\n",
        "        est = np.dot(self.users_f[u], self.books_f[i])\n",
        "\n",
        "        return est\n",
        "        \n",
        "    #to predict all estimated ratings of a user\n",
        "    def EstamedRatingsForUser(self,u):\n",
        "        prid = []\n",
        "        for item in range(self.trainset.n_items):     \n",
        "              rating = self.predict(str(u) , str(self.trainset.to_raw_iid(item)))\n",
        "              prid.append(rating)\n",
        "\n",
        "        return prid"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HybridAlgorithm class, it uses any algo-base class."
      ],
      "metadata": {
        "id": "95pMd-PS5fvi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNB6b9vt-Vo7"
      },
      "outputs": [],
      "source": [
        "class HybridAlgorithm:\n",
        "  def __init__(self, reommendersList):\n",
        "    self.recommenders = reommendersList\n",
        "\n",
        "  def fit(self, trainset):\n",
        "    for algorithm in self.recommenders:\n",
        "      algorithm.fit(trainset)\n",
        "  def predict(self, uid, iid, r_ui=None, clip=True, verbose=False):\n",
        "    predictions = []\n",
        "    for algorithm in self.recommenders:\n",
        "      predictions.append(algorithm.predict(uid, iid, r_ui, clip=True, verbose=False))\n",
        "    mean = 0\n",
        "    for uid, iid, r_ui, est, details in predictions :\n",
        "      mean += est\n",
        "    mean = mean/ len(predictions)\n",
        "    prediction = [predictions[0][0],predictions[0][1],predictions[0][2], mean ,predictions[0][4]]\n",
        "    return prediction\n",
        "  def test(self, testset, verbose=False):\n",
        "    predictions = [\n",
        "            self.predict(uid, iid, r_ui_trans, verbose=verbose)\n",
        "            for (uid, iid, r_ui_trans) in testset ]\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation Data class, the class that provide the necessary data for evaluation."
      ],
      "metadata": {
        "id": "eewOXBlF5tzl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPLjWODumK4p"
      },
      "outputs": [],
      "source": [
        "class EvaluationData:\n",
        "    \n",
        "    def __init__(self, data, popularityRankings):\n",
        "        \n",
        "        self.rankings = popularityRankings\n",
        "        \n",
        "        #Build a full training set for evaluating overall properties\n",
        "        self.fullTrainSet = data.build_full_trainset()\n",
        "        self.fullAntiTestSet = self.fullTrainSet.build_anti_testset()\n",
        "        \n",
        "        #Build a 75/25 train/test split for measuring accuracy\n",
        "        self.trainSet, self.testSet = train_test_split(data, test_size=.25, random_state=1)\n",
        "\n",
        "        #Using our content based recommender to compute similarty matrix between items so we can measure diversity\n",
        "        self.simsAlgo = CBAlgorithm()\n",
        "        print(\"first, let's calculate similarities bettween books with our CB algorithm, so we can measure diversity later ..\")\n",
        "        self.simsAlgo.fit(self.fullTrainSet)\n",
        "        \n",
        "            \n",
        "    def GetFullTrainSet(self):\n",
        "        return self.fullTrainSet\n",
        "    \n",
        "    def GetFullAntiTestSet(self):\n",
        "        return self.fullAntiTestSet\n",
        "    \n",
        "    def GetTrainSet(self):\n",
        "        return self.trainSet\n",
        "    \n",
        "    def GetTestSet(self):\n",
        "        return self.testSet   \n",
        "    \n",
        "    def GetSimilarities(self):\n",
        "        return self.simsAlgo\n",
        "    \n",
        "    def GetPopularityRankings(self):\n",
        "        return self.rankings"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recommender Metrics class, the class that contains the evaluation metrics."
      ],
      "metadata": {
        "id": "hfZTKE6D6EJs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SvWXQq9fkz6"
      },
      "outputs": [],
      "source": [
        "class RecommenderMetrics:\n",
        "\n",
        "    def MAE(predictions):\n",
        "        return accuracy.mae(predictions, verbose=False)\n",
        "\n",
        "    def RMSE(predictions):\n",
        "        return accuracy.rmse(predictions, verbose=False)\n",
        "\n",
        "    def additionalMetrices(self ,rankings,TestData,simsAlgo,ratingThreshold=4.0):\n",
        "\n",
        "      coverage_hits = 0\n",
        "      usersCount=0\n",
        "      n_diversity = 0\n",
        "      total_diversity = 0\n",
        "      n_novelty = 0\n",
        "      total_novelty = 0\n",
        "\n",
        "      for userID in TestData.keys() :\n",
        "              \n",
        "              topN = []\n",
        "\n",
        "              predictions = [self.algorithm.predict(uid, iid, r_ui_trans)\n",
        "                            for (uid, iid, r_ui_trans) in TestData[userID]]\n",
        "\n",
        "              for userID, bookID, actualRating, estimatedRating, _ in predictions:\n",
        "                  topN.append((int(bookID), estimatedRating))\n",
        "\n",
        "              topN.sort(key=lambda x: x[1], reverse=True) \n",
        "              topN = topN[:10]\n",
        "\n",
        "              # calculating coverage\n",
        "\n",
        "              hit = False\n",
        "              if (topN is not []) and (topN [0][1] >= ratingThreshold):\n",
        "                      hit = True\n",
        "              if (hit):\n",
        "                      coverage_hits += 1\n",
        "              \n",
        "              #calculating diversty\n",
        "              pairs = itertools.combinations(topN, 2)\n",
        "              for pair in pairs:\n",
        "                      book1 = pair[0][0]\n",
        "                      book2 = pair[1][0]\n",
        "                      innerID1 = simsAlgo.trainset.to_inner_iid(str(book1))\n",
        "                      innerID2 = simsAlgo.trainset.to_inner_iid(str(book2))\n",
        "                      similarity = simsAlgo.similarities[innerID1,innerID2]\n",
        "                      total_diversity += similarity\n",
        "                      n_diversity += 1\n",
        "\n",
        "              #calculating novelty\n",
        "              for rating in topN:\n",
        "                      bookID = rating[0]\n",
        "                      rank = rankings[bookID]\n",
        "                      total_novelty += rank\n",
        "                      n_novelty += 1\n",
        "              usersCount+=1\n",
        "              \n",
        "      coverty = coverage_hits / usersCount\n",
        "      diversity = (1 - (total_diversity / n_diversity))\n",
        "      novelty= total_novelty / n_novelty\n",
        "      return (coverty,diversity,novelty)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate Algorithm class, the class that implement the evaluation on the algorithm."
      ],
      "metadata": {
        "id": "XRXWiS036PsH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxTNpmRWdD4f"
      },
      "outputs": [],
      "source": [
        "class EvaluatedAlgorithm:\n",
        "    \n",
        "    def __init__(self, algorithm, name):\n",
        "        self.algorithm = algorithm\n",
        "        self.name = name\n",
        "        \n",
        "    def Evaluate(self, evaluationData, n=10, verbose=True):\n",
        "        metrics = {}\n",
        "        # Compute accuracy\n",
        "        if (verbose):\n",
        "            print(\"Evaluating accuracy of \" + self.name + \"  ...\")\n",
        "\n",
        "        self.algorithm.fit(evaluationData.GetTrainSet())\n",
        "        predictions = self.algorithm.test(evaluationData.GetTestSet())\n",
        "\n",
        "        metrics[\"RMSE\"] = RecommenderMetrics.RMSE(predictions)\n",
        "        metrics[\"MAE\"] = RecommenderMetrics.MAE(predictions)\n",
        "\n",
        "        if (verbose):\n",
        "              print(\"Evaluating additional metrics for \" + self.name + \"  ...\")\n",
        "\n",
        "        self.algorithm.fit(evaluationData.GetFullTrainSet())\n",
        "        antiTestSet= evaluationData.GetFullAntiTestSet()\n",
        "\n",
        "        users = defaultdict(list)\n",
        "        for uid, iid, r_ui_trans in antiTestSet:\n",
        "          users[uid].append((uid, iid, r_ui_trans))    \n",
        "\n",
        "        metrics[\"Coverage\"],metrics[\"Diversity\"],metrics[\"Novelty\"]=RecommenderMetrics.additionalMetrices(self\n",
        "                                                                                                          ,TestData=users\n",
        "                                                                                                          ,rankings=evaluationData.GetPopularityRankings()\n",
        "                                                                                                          ,simsAlgo=evaluationData.GetSimilarities())                                         \n",
        "        if (verbose):\n",
        "            print(\"Analysis complete.\")\n",
        "\n",
        "        return metrics\n",
        " \n",
        "    def GetName(self):\n",
        "        return self.name\n",
        "    \n",
        "    def GetAlgorithm(self):\n",
        "        return self.algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluator class, this class implement the evaluation on many algorithms to compare them."
      ],
      "metadata": {
        "id": "iVURczOW6d6N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzeDTaQ1mO2t"
      },
      "outputs": [],
      "source": [
        "class Evaluator:\n",
        "    \n",
        "    algorithms = []\n",
        "    \n",
        "    def __init__(self, dataset, rankings):\n",
        "       \n",
        "        ed = EvaluationData(dataset, rankings)\n",
        "        print(\"done...\")\n",
        "        self.dataset = ed\n",
        "        \n",
        "    def AddAlgorithm(self, algorithm, name):\n",
        "        alg = EvaluatedAlgorithm(algorithm, name)\n",
        "        self.algorithms.append(alg)\n",
        "        \n",
        "    def Evaluate(self):\n",
        "        results = {}\n",
        "        for algorithm in self.algorithms:\n",
        "            print(\"Evaluating \", algorithm.GetName(), \"...\")\n",
        "            results[algorithm.GetName()] = algorithm.Evaluate(self.dataset)\n",
        "\n",
        "        # Print results\n",
        "        print(\"{:<10} {:<10} {:<10}{:<10} {:<10} {:<10}\".format(\"Algorithm\", \"RMSE\", \"MAE\", \"Coverage\", \"Diversity\", \"Novelty\"))\n",
        "        for (name, metrics) in results.items():\n",
        "             print(\"{:<10} {:<10.4f} {:<10.4f}{:<10.4f} {:<10.4f} {:<10.4f}\".format(name, metrics[\"RMSE\"], metrics[\"MAE\"],metrics[\"Coverage\"], metrics[\"Diversity\"], metrics[\"Novelty\"]))\n",
        "                \n",
        "        print(\"metrics:\\n\")\n",
        "        print(\"RMSE:      Root Mean Squared Error. Lower values mean better accuracy.\")\n",
        "        print(\"MAE:       Mean Absolute Error. Lower values mean better accuracy.\")\n",
        "        print(\"Coverage:  Ratio of users for whom recommendations above a certain threshold exist. Higher is better.\")\n",
        "        print(\"Diversity: 1-S, where S is the average similarity score between every possible pair of recommendations\")\n",
        "        print(\"           for a given user. Higher means more diverse.\")\n",
        "        print(\"Novelty:   Average popularity rank of recommended items. Higher means more novel.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can try the hybrid algorithm or any algo-base algorithm with this code"
      ],
      "metadata": {
        "id": "UFr1aszZ60E3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LoadBooksAndRatingsData():\n",
        "    BD = DataProvider()\n",
        "    print(\"Loading book ratings...\")\n",
        "    data = BD.loadData()\n",
        "    #computing book popularity ranks so we can measure novelty later\n",
        "    trainset = data.build_full_trainset()\n",
        "    rankings = BD.getPopularityRanks()\n",
        "    return (BD, trainset , rankings)\n",
        "\n",
        "#now lets use it\n",
        "(BD , data, rankings) = LoadBooksAndRatingsData()\n",
        "\n",
        "CoRecommender  = CoAlgorithm()\n",
        "\n",
        "CBRecommender  = CBAlgorithm()\n",
        "\n",
        "SGDRecommender = SGDAlgorithm()\n",
        "\n",
        "Recommender = HybridAlgorithm ([CoRecommender,CBRecommender,SGDRecommender])\n",
        "\n",
        "Recommender.fit(data)\n",
        "while True:\n",
        "    user= str(input(\"please select a user, select 0 to end the programme:\"))\n",
        "    if user == \"0\":\n",
        "        break\n",
        "    try:\n",
        "        data.to_inner_uid(user)\n",
        "    except:\n",
        "        print(\"invalid user.\")\n",
        "        continue\n",
        "\n",
        "        #get this user ratings\n",
        "    userRatings = BD.getUserRatings(int(user))\n",
        "    loved = []\n",
        "    hated = []\n",
        "    ratings_that_exist = []\n",
        "    for ratings in userRatings:\n",
        "        #to elemenate this books from recommendations later\n",
        "        ratings_that_exist.append(ratings[0])\n",
        "\n",
        "        if (float(ratings[1]) >= 4.0):\n",
        "            loved.append(ratings)\n",
        "        elif float(ratings[1]) < 3.0:\n",
        "            hated.append(ratings)\n",
        "\n",
        "    print(\"\\nUser \", user , \" loved these books:\")\n",
        "    for ratings in loved:\n",
        "        print(BD.getBookName(int(ratings[0]))+\" | with rating :\"+ str(ratings[1]) + \" | geners :\"+str(BD.getStandardGeners()[int(ratings[0])]))\n",
        "    print(\"\\n...and didn't like these books:\")\n",
        "    for ratings in hated:\n",
        "        print(BD.getBookName(int(ratings[0]))+\" | with rating :\"+ str(ratings[1]) + \" | geners :\"+str(BD.getStandardGeners()[int(ratings[0])]))\n",
        "    Predictions = Recommender.EstamedRatingsForUser(user)\n",
        "    #lets convert this data to recommendations\n",
        "    recommendations = []\n",
        "    for uid, iid, r_ui, est, details in Predictions :\n",
        "                    intBookID = int(iid)\n",
        "                    if intBookID not in ratings_that_exist: # to elemenate books that alerdy readed\n",
        "                        recommendations.append((intBookID, est))\n",
        "\n",
        "    #top ratings first\n",
        "    recommendations.sort(key=lambda x: x[1], reverse=True) \n",
        "    print (\"\\nWe recommend:\")     \n",
        "    for ratings in recommendations[:10]:\n",
        "        print(BD.getBookName(ratings[0])+ \" | Estamed rating : \"+ str(ratings[1])+ \" | geners :\"+str(BD.getStandardGeners()[int(ratings[0])])+ \" | year : \"+str(BD.getYears()[int(ratings[0])])+\" | authors : \"+str(BD.getAuthors()[int(ratings[0])]))"
      ],
      "metadata": {
        "id": "ETwtkz136wQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can test the hybrid algorithm or any algo-base algorithm and compare them with this code (this takes a while)"
      ],
      "metadata": {
        "id": "UKOlx-tg7OL6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09aDUqllkH7t",
        "outputId": "944202d8-dbbd-497f-f46f-3198584188ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first, let's calculate similarities bettween books with our CB algorithm, so we can measure diversity later ..\n",
            "Computing content-based similarity matrix...\n",
            "0  of  9736\n",
            "100  of  9736\n",
            "200  of  9736\n",
            "300  of  9736\n",
            "400  of  9736\n",
            "500  of  9736\n",
            "600  of  9736\n",
            "700  of  9736\n",
            "800  of  9736\n",
            "900  of  9736\n",
            "1000  of  9736\n",
            "1100  of  9736\n",
            "1200  of  9736\n",
            "1300  of  9736\n",
            "1400  of  9736\n",
            "1500  of  9736\n",
            "1600  of  9736\n",
            "1700  of  9736\n",
            "1800  of  9736\n",
            "1900  of  9736\n",
            "2000  of  9736\n",
            "2100  of  9736\n",
            "2200  of  9736\n",
            "2300  of  9736\n",
            "2400  of  9736\n",
            "2500  of  9736\n",
            "2600  of  9736\n",
            "2700  of  9736\n",
            "2800  of  9736\n",
            "2900  of  9736\n",
            "3000  of  9736\n",
            "3100  of  9736\n",
            "3200  of  9736\n",
            "3300  of  9736\n",
            "3400  of  9736\n",
            "3500  of  9736\n",
            "3600  of  9736\n",
            "3700  of  9736\n",
            "3800  of  9736\n",
            "3900  of  9736\n",
            "4000  of  9736\n",
            "4100  of  9736\n",
            "4200  of  9736\n",
            "4300  of  9736\n",
            "4400  of  9736\n",
            "4500  of  9736\n",
            "4600  of  9736\n",
            "4700  of  9736\n",
            "4800  of  9736\n",
            "4900  of  9736\n",
            "5000  of  9736\n",
            "5100  of  9736\n",
            "5200  of  9736\n",
            "5300  of  9736\n",
            "5400  of  9736\n",
            "5500  of  9736\n",
            "5600  of  9736\n",
            "5700  of  9736\n",
            "5800  of  9736\n",
            "5900  of  9736\n",
            "6000  of  9736\n",
            "6100  of  9736\n",
            "6200  of  9736\n",
            "6300  of  9736\n",
            "6400  of  9736\n",
            "6500  of  9736\n",
            "6600  of  9736\n",
            "6700  of  9736\n",
            "6800  of  9736\n",
            "6900  of  9736\n",
            "7000  of  9736\n",
            "7100  of  9736\n",
            "7200  of  9736\n",
            "7300  of  9736\n",
            "7400  of  9736\n",
            "7500  of  9736\n",
            "7600  of  9736\n",
            "7700  of  9736\n",
            "7800  of  9736\n",
            "7900  of  9736\n",
            "8000  of  9736\n",
            "8100  of  9736\n",
            "8200  of  9736\n",
            "8300  of  9736\n",
            "8400  of  9736\n",
            "8500  of  9736\n",
            "8600  of  9736\n",
            "8700  of  9736\n",
            "8800  of  9736\n",
            "8900  of  9736\n",
            "9000  of  9736\n",
            "9100  of  9736\n",
            "9200  of  9736\n",
            "9300  of  9736\n",
            "9400  of  9736\n",
            "9500  of  9736\n",
            "9600  of  9736\n",
            "9700  of  9736\n",
            "...done.\n",
            "done...\n",
            "Evaluating  HybridRecommender ...\n",
            "Evaluating accuracy of HybridRecommender  ...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing content-based similarity matrix...\n",
            "0  of  9637\n",
            "100  of  9637\n",
            "200  of  9637\n",
            "300  of  9637\n",
            "400  of  9637\n",
            "500  of  9637\n",
            "600  of  9637\n",
            "700  of  9637\n",
            "800  of  9637\n",
            "900  of  9637\n",
            "1000  of  9637\n",
            "1100  of  9637\n",
            "1200  of  9637\n",
            "1300  of  9637\n",
            "1400  of  9637\n",
            "1500  of  9637\n",
            "1600  of  9637\n",
            "1700  of  9637\n",
            "1800  of  9637\n",
            "1900  of  9637\n",
            "2000  of  9637\n",
            "2100  of  9637\n",
            "2200  of  9637\n",
            "2300  of  9637\n",
            "2400  of  9637\n",
            "2500  of  9637\n",
            "2600  of  9637\n",
            "2700  of  9637\n",
            "2800  of  9637\n",
            "2900  of  9637\n",
            "3000  of  9637\n",
            "3100  of  9637\n",
            "3200  of  9637\n",
            "3300  of  9637\n",
            "3400  of  9637\n",
            "3500  of  9637\n",
            "3600  of  9637\n",
            "3700  of  9637\n",
            "3800  of  9637\n",
            "3900  of  9637\n",
            "4000  of  9637\n",
            "4100  of  9637\n",
            "4200  of  9637\n",
            "4300  of  9637\n",
            "4400  of  9637\n",
            "4500  of  9637\n",
            "4600  of  9637\n",
            "4700  of  9637\n",
            "4800  of  9637\n",
            "4900  of  9637\n",
            "5000  of  9637\n",
            "5100  of  9637\n",
            "5200  of  9637\n",
            "5300  of  9637\n",
            "5400  of  9637\n",
            "5500  of  9637\n",
            "5600  of  9637\n",
            "5700  of  9637\n",
            "5800  of  9637\n",
            "5900  of  9637\n",
            "6000  of  9637\n",
            "6100  of  9637\n",
            "6200  of  9637\n",
            "6300  of  9637\n",
            "6400  of  9637\n",
            "6500  of  9637\n",
            "6600  of  9637\n",
            "6700  of  9637\n",
            "6800  of  9637\n",
            "6900  of  9637\n",
            "7000  of  9637\n",
            "7100  of  9637\n",
            "7200  of  9637\n",
            "7300  of  9637\n",
            "7400  of  9637\n",
            "7500  of  9637\n",
            "7600  of  9637\n",
            "7700  of  9637\n",
            "7800  of  9637\n",
            "7900  of  9637\n",
            "8000  of  9637\n",
            "8100  of  9637\n",
            "8200  of  9637\n",
            "8300  of  9637\n",
            "8400  of  9637\n",
            "8500  of  9637\n",
            "8600  of  9637\n",
            "8700  of  9637\n",
            "8800  of  9637\n",
            "8900  of  9637\n",
            "9000  of  9637\n",
            "9100  of  9637\n",
            "9200  of  9637\n",
            "9300  of  9637\n",
            "9400  of  9637\n",
            "9500  of  9637\n",
            "9600  of  9637\n",
            "...done.\n",
            "Evaluating additional metrics for HybridRecommender  ...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing content-based similarity matrix...\n",
            "0  of  9736\n",
            "100  of  9736\n",
            "200  of  9736\n",
            "300  of  9736\n",
            "400  of  9736\n",
            "500  of  9736\n",
            "600  of  9736\n",
            "700  of  9736\n",
            "800  of  9736\n",
            "900  of  9736\n",
            "1000  of  9736\n",
            "1100  of  9736\n",
            "1200  of  9736\n",
            "1300  of  9736\n",
            "1400  of  9736\n",
            "1500  of  9736\n",
            "1600  of  9736\n",
            "1700  of  9736\n",
            "1800  of  9736\n",
            "1900  of  9736\n",
            "2000  of  9736\n",
            "2100  of  9736\n",
            "2200  of  9736\n",
            "2300  of  9736\n",
            "2400  of  9736\n",
            "2500  of  9736\n",
            "2600  of  9736\n",
            "2700  of  9736\n",
            "2800  of  9736\n",
            "2900  of  9736\n",
            "3000  of  9736\n",
            "3100  of  9736\n",
            "3200  of  9736\n",
            "3300  of  9736\n",
            "3400  of  9736\n",
            "3500  of  9736\n",
            "3600  of  9736\n",
            "3700  of  9736\n",
            "3800  of  9736\n",
            "3900  of  9736\n",
            "4000  of  9736\n",
            "4100  of  9736\n",
            "4200  of  9736\n",
            "4300  of  9736\n",
            "4400  of  9736\n",
            "4500  of  9736\n",
            "4600  of  9736\n",
            "4700  of  9736\n",
            "4800  of  9736\n",
            "4900  of  9736\n",
            "5000  of  9736\n",
            "5100  of  9736\n",
            "5200  of  9736\n",
            "5300  of  9736\n",
            "5400  of  9736\n",
            "5500  of  9736\n",
            "5600  of  9736\n",
            "5700  of  9736\n",
            "5800  of  9736\n",
            "5900  of  9736\n",
            "6000  of  9736\n",
            "6100  of  9736\n",
            "6200  of  9736\n",
            "6300  of  9736\n",
            "6400  of  9736\n",
            "6500  of  9736\n",
            "6600  of  9736\n",
            "6700  of  9736\n",
            "6800  of  9736\n",
            "6900  of  9736\n",
            "7000  of  9736\n",
            "7100  of  9736\n",
            "7200  of  9736\n",
            "7300  of  9736\n",
            "7400  of  9736\n",
            "7500  of  9736\n",
            "7600  of  9736\n",
            "7700  of  9736\n",
            "7800  of  9736\n",
            "7900  of  9736\n",
            "8000  of  9736\n",
            "8100  of  9736\n",
            "8200  of  9736\n",
            "8300  of  9736\n",
            "8400  of  9736\n",
            "8500  of  9736\n",
            "8600  of  9736\n",
            "8700  of  9736\n",
            "8800  of  9736\n",
            "8900  of  9736\n",
            "9000  of  9736\n",
            "9100  of  9736\n",
            "9200  of  9736\n",
            "9300  of  9736\n",
            "9400  of  9736\n",
            "9500  of  9736\n",
            "9600  of  9736\n",
            "9700  of  9736\n",
            "...done.\n",
            "Analysis complete.\n",
            "Algorithm  RMSE       MAE       Coverage   Diversity  Novelty   \n",
            "HybridRecommender 0.8444     0.6684    0.9538     0.6930     5261.7557 \n",
            "metrics:\n",
            "\n",
            "RMSE:      Root Mean Squared Error. Lower values mean better accuracy.\n",
            "MAE:       Mean Absolute Error. Lower values mean better accuracy.\n",
            "Coverage:  Ratio of users for whom recommendations above a certain threshold exist. Higher is better.\n",
            "Diversity: 1-S, where S is the average similarity score between every possible pair of recommendations\n",
            "           for a given user. Higher means more diverse.\n",
            "Novelty:   Average popularity rank of recommended items. Higher means more novel.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def LoadBooksAndRatingsData():\n",
        "    BD = DataProvider()\n",
        "    print(\"Loading book ratings...\")\n",
        "    data = BD.loadData()\n",
        "    #computing book popularity ranks so we can measure novelty later\n",
        "    rankings = BD.getPopularityRanks()\n",
        "    return (BD, data , rankings)\n",
        "\n",
        "#now lets use it\n",
        "(BD , data  , rankings) = LoadBooksAndRatingsData()\n",
        "evaluator = Evaluator(data, rankings)\n",
        "\n",
        "# User-based KNN\n",
        "CoRecommender  = CoAlgorithm()\n",
        "evaluator.AddAlgorithm(CoRecommender, \"CoRecommender\")\n",
        "\n",
        "# CB-based Algorithm\n",
        "CBRecommender  = CBAlgorithm()\n",
        "evaluator.AddAlgorithm(CBRecommender, \"CBRecommender\")\n",
        "\n",
        "#our SGD now\n",
        "SGDRecommender = SGDAlgorithm()\n",
        "evaluator.AddAlgorithm(SGDRecommender, \"SGDRecommender\")\n",
        "\n",
        "CoRecommender  = CoAlgorithm()\n",
        "\n",
        "CBRecommender  = CBAlgorithm()\n",
        "\n",
        "SGDRecommender = SGDAlgorithm()\n",
        "\n",
        "HybridRecommender = HybridAlgorithm ([CoRecommender,CBRecommender,SGDRecommender])\n",
        "\n",
        "evaluator.AddAlgorithm(HybridRecommender, \"HybridRecommender\")\n",
        "\n",
        "#standar NMF now\n",
        "standardNMF = NMF(n_epochs=20,n_factors=20)\n",
        "evaluator.AddAlgorithm(standardNMF, \"NMF\")\n",
        "\n",
        "# KNNBasic\n",
        "standardClustering = KNNBasic()\n",
        "evaluator.AddAlgorithm(standardClustering, \"KNNBasic\")\n",
        "\n",
        "# Just make random recommendations\n",
        "Random = NormalPredictor()\n",
        "evaluator.AddAlgorithm(Random, \"Random\")\n",
        "\n",
        "# Test !\n",
        "evaluator.Evaluate()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}